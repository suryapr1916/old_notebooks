{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of deep_crossentropy_method.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFgmtr8_eE43"
      },
      "source": [
        "# Deep Crossentropy method\n",
        "\n",
        "In this section we'll extend your CEM implementation with neural networks! You will train a multi-layer neural network to solve simple continuous state space games. __Please make sure you're done with tabular crossentropy method from the previous notebook.__\n",
        "\n",
        "![img](https://tip.duke.edu/independent_learning/greek/lesson/digging_deeper_final.jpg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwxiMkz3eE44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b1625002-e580-4cb6-934d-a4ce70f66039"
      },
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/spring20/setup_colab.sh -O- | bash\n",
        "\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/grading.py -O ../grading.py\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/week1_intro/submit.py\n",
        "\n",
        "    !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting virtual X frame buffer: Xvfb.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFBZFOTDeE48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "b5b8ac31-cbd6-4224-f09e-19fa9d1e1405"
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# if you see \"<classname> has no attribute .env\", remove .env or update gym\n",
        "env = gym.make(\"CartPole-v0\").env\n",
        "\n",
        "env.reset()\n",
        "n_actions = env.action_space.n\n",
        "state_dim = env.observation_space.shape[0]\n",
        "\n",
        "plt.imshow(env.render(\"rgb_array\"))\n",
        "print(\"state vector dim =\", state_dim)\n",
        "print(\"n_actions =\", n_actions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "state vector dim = 4\n",
            "n_actions = 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCZOOmrdeE5A"
      },
      "source": [
        "# Neural Network Policy\n",
        "\n",
        "For this assignment we'll utilize the simplified neural network implementation from __[Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)__. Here's what you'll need:\n",
        "\n",
        "* `agent.partial_fit(states, actions)` - make a single training pass over the data. Maximize the probabilitity of :actions: from :states:\n",
        "* `agent.predict_proba(states)` - predict probabilities of all actions, a matrix of shape __[len(states), n_actions]__\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssbHkJ0beE5B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "70be5982-297d-4c62-a5f2-953f934c34e5"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "agent = MLPClassifier(\n",
        "    hidden_layer_sizes=(20, 20),\n",
        "    activation='tanh',\n",
        ")\n",
        "\n",
        "# initialize agent to the dimension of state space and number of actions\n",
        "agent.partial_fit([env.reset()] * n_actions, range(n_actions), range(n_actions))\n",
        "print(n_actions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKO5WvYSeE5E"
      },
      "source": [
        "def generate_session(env, agent, t_max=1000):\n",
        "    \"\"\"\n",
        "    Play a single game using agent neural network.\n",
        "    Terminate when game finishes or after :t_max: steps\n",
        "    \"\"\"\n",
        "    states, actions = [], []\n",
        "    total_reward = 0\n",
        "\n",
        "    s = env.reset()\n",
        "\n",
        "    for t in range(t_max):\n",
        "        \n",
        "        # use agent to predict a vector of action probabilities for state :s:\n",
        "        k = agent.predict_proba([s]*n_actions)\n",
        "        probs = k[np.argmax(k.sum(axis=0))]\n",
        "        \n",
        "        assert probs.shape == (n_actions,), \"make sure probabilities are a vector (hint: np.reshape)\"\n",
        "        \n",
        "        # use the probabilities you predicted to pick an action\n",
        "        # sample proportionally to the probabilities, don't just take the most likely action\n",
        "        a = np.random.choice(n_actions, p = probs)\n",
        "        # ^-- hint: try np.random.choice\n",
        "\n",
        "        new_s, r, done, info = env.step(a)\n",
        "\n",
        "        # record sessions like you did before\n",
        "        states.append(s)\n",
        "        actions.append(a)\n",
        "        total_reward += r\n",
        "\n",
        "        s = new_s\n",
        "        if done:\n",
        "            break\n",
        "    return states, actions, total_reward"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iunLC5CGeE5G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "26ee22bd-2c34-4624-e8fb-7f7c7744028c"
      },
      "source": [
        "dummy_states, dummy_actions, dummy_reward = generate_session(env, agent, t_max=5)\n",
        "print(\"states:\", np.stack(dummy_states))\n",
        "print(\"actions:\", dummy_actions)\n",
        "print(\"reward:\", dummy_reward)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "states: [[-0.04291995 -0.01355253 -0.00622371 -0.03005803]\n",
            " [-0.043191   -0.20858467 -0.00682487  0.26065477]\n",
            " [-0.04736269 -0.01336597 -0.00161177 -0.03417297]\n",
            " [-0.04763001 -0.20846477 -0.00229523  0.25800099]\n",
            " [-0.05179931 -0.40355387  0.00286479  0.54995908]]\n",
            "actions: [0, 1, 0, 0, 1]\n",
            "reward: 5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhF1iafpeE5J"
      },
      "source": [
        "### CEM steps\n",
        "Deep CEM uses exactly the same strategy as the regular CEM, so you can copy your function code from previous notebook.\n",
        "\n",
        "The only difference is that now each observation is not a number but a `float32` vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4URJhzxReE5J"
      },
      "source": [
        "def select_elites(states_batch, actions_batch, rewards_batch, percentile=50):\n",
        "    \"\"\"\n",
        "    Select states and actions from games that have rewards >= percentile\n",
        "    :param states_batch: list of lists of states, states_batch[session_i][t]\n",
        "    :param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
        "    :param rewards_batch: list of rewards, rewards_batch[session_i]\n",
        "\n",
        "    :returns: elite_states,elite_actions, both 1D lists of states and respective actions from elite sessions\n",
        "\n",
        "    Please return elite states and actions in their original order \n",
        "    [i.e. sorted by session number and timestep within session]\n",
        "\n",
        "    If you are confused, see examples below. Please don't assume that states are integers\n",
        "    (they will become different later).\n",
        "    \"\"\"\n",
        "\n",
        "   # <YOUR CODE: copy-paste your implementation from the previous notebook>\n",
        "    reward_threshold = np.percentile(rewards_batch,percentile) \n",
        "    elite_states = []\n",
        "    elite_actions = []\n",
        "    a = list(np.array(states_batch)[np.array(rewards_batch)>=reward_threshold])\n",
        "    for i in a:\n",
        "      for j in i:\n",
        "        elite_states.append(j)\n",
        "    b = list(np.array(actions_batch)[np.array(rewards_batch)>=reward_threshold])\n",
        "    for i in b:\n",
        "      for j in i:\n",
        "        elite_actions.append(j)\n",
        "\n",
        "    return elite_states, elite_actions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTwoZxuCeE5M"
      },
      "source": [
        "# Training loop\n",
        "Generate sessions, select N best and fit to those."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8969dHSeE5M"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "def show_progress(rewards_batch, log, percentile, reward_range=[-990, +10]):\n",
        "    \"\"\"\n",
        "    A convenience function that displays training progress. \n",
        "    No cool math here, just charts.\n",
        "    \"\"\"\n",
        "\n",
        "    mean_reward = np.mean(rewards_batch)\n",
        "    threshold = np.percentile(rewards_batch, percentile)\n",
        "    log.append([mean_reward, threshold])\n",
        "\n",
        "    clear_output(True)\n",
        "    print(\"mean reward = %.3f, threshold=%.3f\" % (mean_reward, threshold))\n",
        "    plt.figure(figsize=[8, 4])\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(list(zip(*log))[0], label='Mean rewards')\n",
        "    plt.plot(list(zip(*log))[1], label='Reward thresholds')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(rewards_batch, range=reward_range)\n",
        "    plt.vlines([np.percentile(rewards_batch, percentile)],\n",
        "               [0], [100], label=\"percentile\", color='red')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9zzHxwceE5P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        },
        "outputId": "1493a11a-7359-40f9-b23d-3d78be8704ce"
      },
      "source": [
        "n_sessions = 100\n",
        "percentile = 70\n",
        "log = []\n",
        "\n",
        "for i in range(100):\n",
        "    # generate new sessions\n",
        "    #sessions = [ <YOUR CODE: generate a list of n_sessions new sessions> ]\n",
        "\n",
        "    %time sessions = [generate_session(env, agent) for j in range(n_sessions)]\n",
        "\n",
        "\n",
        "    states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
        "\n",
        "    elite_states, elite_actions = select_elites(states_batch, actions_batch, rewards_batch, percentile = percentile)\n",
        "\n",
        "    #<YOUR CODE: partial_fit agent to predict elite_actions(y) from elite_states(X)>\n",
        "    agent.partial_fit(elite_states, elite_actions, elite_actions)\n",
        "    #agent.predict_proba(states_batch)\n",
        "    show_progress(rewards_batch, log, percentile, reward_range=[0, np.max(rewards_batch)])\n",
        "\n",
        "    if np.mean(rewards_batch) > 190:\n",
        "        print(\"You Win! You may stop training now via KeyboardInterrupt.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean reward = 998.330, threshold=1000.000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "You Win! You may stop training now via KeyboardInterrupt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-970255cba176>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#sessions = [ <YOUR CODE: generate a list of n_sessions new sessions> ]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time sessions = [generate_session(env, agent) for j in range(n_sessions)]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2079\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-5f3cdc8222d3>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(env, agent, t_max)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# use agent to predict a vector of action probabilities for state :s:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \"\"\"\n\u001b[1;32m   1071\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mdecision\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \"\"\"\n\u001b[0;32m--> 667\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;31m# Make sure self.hidden_layer_sizes is a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJxqY293eE5R"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri-pZL26eE5S"
      },
      "source": [
        "# Record sessions\n",
        "\n",
        "import gym.wrappers\n",
        "\n",
        "with gym.wrappers.Monitor(gym.make(\"CartPole-v0\"), directory=\"videos\", force=True) as env_monitor:\n",
        "    sessions = [generate_session(env_monitor, agent) for _ in range(100)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNQ3BpXxeE5U",
        "colab": {
          "resources": {
            "http://localhost:8080/videos/openaigym.video.0.100.video000064.mp4": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "outputId": "e0ceb5e4-481b-4107-85d4-d586059ccc69"
      },
      "source": [
        "# Show video. This may not work in some setups. If it doesn't\n",
        "# work for you, you can download the videos and view them locally.\n",
        "\n",
        "from pathlib import Path\n",
        "from IPython.display import HTML\n",
        "\n",
        "video_names = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
        "\n",
        "HTML(\"\"\"\n",
        "<video width=\"640\" height=\"480\" controls>\n",
        "  <source src=\"{}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\".format(video_names[-1]))  # You can also try other indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<video width=\"640\" height=\"480\" controls>\n",
              "  <source src=\"videos/openaigym.video.0.100.video000064.mp4\" type=\"video/mp4\">\n",
              "</video>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEfHJRGueE5W"
      },
      "source": [
        "## Assignment: MountainCar\n",
        "\n",
        "By this moment you should have got enough score on [CartPole-v0](https://gym.openai.com/envs/CartPole-v0) to consider it solved (see the link). It's time to try something harder.\n",
        "\n",
        "_if you have any trouble with CartPole-v0 and feel stuck, take a look at the forums_\n",
        "\n",
        "Your assignment is to obtain average reward of __at least -150__ on `MountainCar-v0`.\n",
        "\n",
        "See the tips section below, it's kinda important.\n",
        "  \n",
        "* Bonus quest: Devise a way to speed up training against the default version\n",
        "  * Obvious improvement: use [joblib](https://www.google.com/search?client=ubuntu&channel=fs&q=joblib&ie=utf-8&oe=utf-8)\n",
        "  * Try re-using samples from 3-5 last iterations when computing threshold and training\n",
        "  * Experiment with amount of training iterations and learning rate of the neural network (see params)\n",
        "  \n",
        "  \n",
        "### Tips\n",
        "* Gym page: [MountainCar](https://gym.openai.com/envs/MountainCar-v0)\n",
        "* Sessions for MountainCar may last for 10k+ ticks. Make sure ```t_max``` param is at least 10k.\n",
        " * Also it may be a good idea to cut rewards via \">\" and not \">=\". If 90% of your sessions get reward of -10k and 10% are better, than if you use percentile 20% as threshold, R >= threshold __fails cut off bad sessions__ whule R > threshold works alright.\n",
        "* _issue with gym_: Some versions of gym limit game time by 200 ticks. This will prevent cem training in most cases. Make sure your agent is able to play for the specified __t_max__, and if it isn't, try `env = gym.make(\"MountainCar-v0\").env` or otherwise get rid of TimeLimit wrapper.\n",
        "* If it won't train it's a good idea to plot reward distribution and record sessions: they may give you some clue. If they don't, call course staff :)\n",
        "* 20-neuron network is probably not enough, feel free to experiment.\n",
        "\n",
        "You may find the following snippet useful:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfpVSqxLW8YA"
      },
      "source": [
        "env = gym.make(\"MountainCar-v0\").env\n",
        "\n",
        "env.reset()\n",
        "n_actions = env.action_space.n\n",
        "state_dim = env.observation_space.shape[0]\n",
        "\n",
        "plt.imshow(env.render(\"rgb_array\"))\n",
        "print(\"state vector dim =\", state_dim)\n",
        "print(\"n_actions =\", n_actions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqqNRLWoW8vZ"
      },
      "source": [
        "agent = MLPClassifier(\n",
        "    hidden_layer_sizes=(40, 40),\n",
        "    activation='tanh'\n",
        ")\n",
        "\n",
        "# initialize agent to the dimension of state space and number of actions\n",
        "agent.partial_fit([env.reset()] * n_actions, range(n_actions), range(n_actions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCa8GzeQeE5Z"
      },
      "source": [
        "def visualize_mountain_car(env, agent):\n",
        "    xs = np.linspace(env.min_position, env.max_position, 100)\n",
        "    vs = np.linspace(-env.max_speed, env.max_speed, 100)\n",
        "    grid = np.dstack(np.meshgrid(xs, vs)).transpose(1, 0, 2)\n",
        "    grid_flat = grid.reshape(len(xs) * len(vs), 2)\n",
        "    probs = agent.predict_proba(grid_flat).reshape(len(xs), len(vs), 3)\n",
        "    return probs\n",
        "\n",
        "with gym.make('MountainCar-v0').env as env_vis:\n",
        "    plt.imshow(visualize_mountain_car(env_vis, agent))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxeTxRs7eE5c"
      },
      "source": [
        "# Implement generate_session_mountain_car(), training loop, etc.\n",
        "import joblib\n",
        "from joblib import Parallel, delayed\n",
        "def generate_session_mountain_car(env=env, agent=agent, t_max=15000):\n",
        "    states, actions = [], []\n",
        "    total_reward = 0\n",
        "\n",
        "    s = env.reset()\n",
        "    env.reset()\n",
        "\n",
        "\n",
        "    for t in range(t_max):\n",
        "        \n",
        "        # use agent to predict a vector of action probabilities for state :s:\n",
        "        k = agent.predict_proba([s]*n_actions)\n",
        "        probs = k[np.argmax(k.sum(axis=0))]\n",
        "        \n",
        "        assert probs.shape == (n_actions,), \"make sure probabilities are a vector (hint: np.reshape)\"\n",
        "        \n",
        "        # use the probabilities you predicted to pick an action\n",
        "        # sample proportionally to the probabilities, don't just take the most likely action\n",
        "        a = np.random.choice(n_actions, p = probs)\n",
        "        # ^-- hint: try np.random.choice\n",
        "\n",
        "        new_s, r, done, info = env.step(a)\n",
        "\n",
        "        # record sessions like you did before\n",
        "        states.append(s)\n",
        "        actions.append(a)\n",
        "        total_reward += r\n",
        "\n",
        "        s = new_s\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    env.close()\n",
        "    \n",
        "    return [states, actions, total_reward]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTZ7oTOJXrur"
      },
      "source": [
        "def select_elites_2(states_batch, actions_batch, rewards_batch, percentile=90):\n",
        "    \"\"\"\n",
        "    Select states and actions from games that have rewards >= percentile\n",
        "    :param states_batch: list of lists of states, states_batch[session_i][t]\n",
        "    :param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
        "    :param rewards_batch: list of rewards, rewards_batch[session_i]\n",
        "\n",
        "    :returns: elite_states,elite_actions, both 1D lists of states and respective actions from elite sessions\n",
        "\n",
        "    Please return elite states and actions in their original order \n",
        "    [i.e. sorted by session number and timestep within session]\n",
        "\n",
        "    If you are confused, see examples below. Please don't assume that states are integers\n",
        "    (they will become different later).\n",
        "    \"\"\"\n",
        "\n",
        "   # <YOUR CODE: copy-paste your implementation from the previous notebook>\n",
        "    reward_threshold = np.percentile(rewards_batch,percentile) \n",
        "    elite_states = []\n",
        "    elite_actions = []\n",
        "    a = list(np.array(states_batch)[np.array(rewards_batch)>reward_threshold])\n",
        "    for i in a:\n",
        "      for j in i:\n",
        "        elite_states.append(j)\n",
        "    b = list(np.array(actions_batch)[np.array(rewards_batch)>reward_threshold])\n",
        "    for i in b:\n",
        "      for j in i:\n",
        "        elite_actions.append(j)\n",
        "\n",
        "    return elite_states, elite_actions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SkcWJFCYiGR"
      },
      "source": [
        "n_sessions = 100\n",
        "percentile = 77\n",
        "log = []\n",
        "\n",
        "for i in range(20):\n",
        "    #generate new sessions\n",
        "#     sessions = [<generate a list of n_sessions new sessions>]\n",
        "    #sessions = [generate_session_mountain_car(agent=agent) for i in range(n_sessions)\n",
        "    sessions = Parallel(n_jobs=-1,backend=\"threading\")(delayed(generate_session_mountain_car)() for i in range(n_sessions))\n",
        "\n",
        "\n",
        "    states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
        "\n",
        "    elite_states, elite_actions = select_elites_2(states_batch, actions_batch, rewards_batch, percentile = percentile)\n",
        "\n",
        "    #<YOUR CODE: partial_fit agent to predict elite_actions(y) from elite_states(X)>\n",
        "    agent.partial_fit(elite_states, elite_actions, elite_actions)\n",
        "    \n",
        "    show_progress(rewards_batch, log, percentile, reward_range=[-15000, np.max(rewards_batch)])\n",
        "\n",
        "    if np.mean(rewards_batch) > 190:\n",
        "        print(\"You Win! You may stop training now via KeyboardInterrupt.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdlLHBF3eE5e"
      },
      "source": [
        "### Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDPswNYPdmoU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}